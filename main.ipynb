{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic modelling module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots be included into this doc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.core.display import display, HTML\n",
    "from bin.model import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from bin.conf import PREDICTOR_LOADERS\n",
    "from bin.loader import get_predictor_data\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DATA_PATH = './data' # relative (or absolute) path to the data directory\n",
    "CSV_SEPARATOR = r'\\t' # separator used in csv data files\n",
    "DATA_FILE_NAMES = ['broad_leaf_GBIF.csv', 'широколиственные.csv'] # all data files should be in the same format\n",
    "ALLOWED_COLUMNS = ['species', 'latitude', 'longitude'] # only these columns will be retained for computations\n",
    "COLUMNS_DTYPES = [np.str, np.float64, np.float64] # Should have the same length as ALLOWED_COLUMNS\n",
    "MODEL_SPECIES = ['quercus mongolica', 'fraxinus mandshurica'] # all  species should be given in lowercase format\n",
    "\n",
    "# Initial set of variables (see conf.py: PREDICTOR_LOADERS parameter for details)\n",
    "VARIABLE_SET = tuple(['BIO' + str(k) for k in range(1, 20)])\n",
    "#VARIABLE_SET += ('WKI5', 'CKI5', 'PWKI0', 'PCKI0','IT', 'IC', 'TMINM', 'TMAXM')\n",
    "#VARIABLE_SET += tuple(['PREC' + str(k) for k in range(1, 13)])\n",
    "#VARIABLE_SET += tuple(['TAVG' + str(k) for k in range(1, 13)])\n",
    "#VARIABLE_SET += tuple(['WKI' + str(k) for k in range(2, 7)])\n",
    "#VARIABLE_SET += tuple(['CKI' + str(k) for k in range(2, 7)])\n",
    "CLASSIFIERS = [#('Naive Bayes', GaussianNB()),\n",
    "               ('MaxEnt', LogisticRegression()),\n",
    "               ('LDA', LinearDiscriminantAnalysis())\n",
    "              ]\n",
    "KFOLDS_NUMBER = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file broad_leaf_GBIF.csv succesfully loaded.\n",
      "File overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3036 entries, 0 to 3035\n",
      "Data columns (total 4 columns):\n",
      "species        3036 non-null object\n",
      "countrycode    3036 non-null object\n",
      "latitude       3034 non-null float64\n",
      "longitude      3034 non-null float64\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 95.0+ KB\n",
      "==================================================\n",
      "The file широколиственные.csv succesfully loaded.\n",
      "File overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 605 entries, 0 to 604\n",
      "Data columns (total 3 columns):\n",
      "species      605 non-null object\n",
      "latitude     604 non-null float64\n",
      "longitude    604 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 14.3+ KB\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Original size: 3641</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>The size after duplications removal: 2042</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_presence_data = pd.DataFrame({col: [] for col in ALLOWED_COLUMNS}) #initialize dataframe-accumulator\n",
    "for filename in DATA_FILE_NAMES:\n",
    "    try:\n",
    "        # data loading procedure\n",
    "        data = pd.read_csv(os.path.join(SOURCE_DATA_PATH, filename),\n",
    "                           sep=CSV_SEPARATOR, dtype={a:b for a,b in zip(ALLOWED_COLUMNS, COLUMNS_DTYPES)})\n",
    "    except IOError:\n",
    "        print(\"Couldn't read the file %s.\" % filename)\n",
    "    if any(data):\n",
    "        print('The file %s succesfully loaded.' % filename)\n",
    "        print('File overview:')\n",
    "        data.info()\n",
    "        print('='*50)\n",
    "    # data concatenation procedure\n",
    "    original_presence_data = pd.concat([original_presence_data, data[ALLOWED_COLUMNS]], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# make species names lowercased and stripped\n",
    "original_presence_data['species'] = original_presence_data['species'].apply(str.lower).apply(str.strip)\n",
    "\n",
    "display(HTML('<h3>Original size: %s</h3>'%original_presence_data['species'].size))\n",
    "\n",
    "# remove duplicate rows and nan values\n",
    "original_presence_data = original_presence_data.dropna().drop_duplicates(ALLOWED_COLUMNS).reset_index(drop=True)\n",
    "display(HTML('<h3>The size after duplications removal: %s</h3>'%original_presence_data['species'].size))\n",
    "\n",
    "\n",
    "# remove duplicate values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>General info:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2042 entries, 0 to 2041\n",
      "Data columns (total 3 columns):\n",
      "latitude     2042 non-null float64\n",
      "longitude    2042 non-null float64\n",
      "species      2042 non-null object\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 47.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Species occurences overview:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "quercus mongolica         329\n",
       "kalopanax septemlobus     292\n",
       "carpinus cordata          285\n",
       "fraxinus lanuginosa       274\n",
       "juglans mandshurica       269\n",
       "quercus crispula          158\n",
       "phellodendron amurense    144\n",
       "ulmus davidiana           130\n",
       "acer pictum                75\n",
       "fraxinus mandshurica       40\n",
       "juglans ailanthifolia      22\n",
       "tilia amurensis            11\n",
       "abies holophylla            8\n",
       "quercus crispula blume      5\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(HTML('<h3>General info:</h3>'))\n",
    "original_presence_data.info()\n",
    "display(HTML('<h3>Species occurences overview:</h3>'))\n",
    "original_presence_data['species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN LOOP OVER ALL SPECIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>=============== quercus mongolica ======================</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing the dataset...\n",
      "Dataset is formed.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 721 entries, 0 to 720\n",
      "Data columns (total 23 columns):\n",
      "absence      721 non-null bool\n",
      "latitude     721 non-null float64\n",
      "longitude    721 non-null float64\n",
      "species      721 non-null object\n",
      "BIO1         721 non-null float64\n",
      "BIO2         721 non-null float64\n",
      "BIO3         721 non-null float64\n",
      "BIO4         721 non-null float64\n",
      "BIO5         721 non-null float64\n",
      "BIO6         721 non-null float64\n",
      "BIO7         721 non-null float64\n",
      "BIO8         721 non-null float64\n",
      "BIO9         721 non-null float64\n",
      "BIO10        721 non-null float64\n",
      "BIO11        721 non-null float64\n",
      "BIO12        721 non-null float64\n",
      "BIO13        721 non-null float64\n",
      "BIO14        721 non-null float64\n",
      "BIO15        721 non-null float64\n",
      "BIO16        721 non-null float64\n",
      "BIO17        721 non-null float64\n",
      "BIO18        721 non-null float64\n",
      "BIO19        721 non-null float64\n",
      "dtypes: bool(1), float64(21), object(1)\n",
      "memory usage: 124.7+ KB\n",
      "Preforming recursive feature ellimination for the <MaxEnt> classifier...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The classifier does not expose \"coef_\" or \"feature_importances_\" attributes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3c8bdbce1019>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         rfecv_acc = RFECV(estimator=std_clf, step=1, cv=StratifiedKFold(KFOLDS_NUMBER),\n\u001b[1;32m     21\u001b[0m                       scoring='accuracy')\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mrfecv_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy case\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimal composition of variables: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVARIABLE_SET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrfecv_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    434\u001b[0m         scores = parallel(\n\u001b[1;32m    435\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             for train, test in cv.split(X, y))\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    434\u001b[0m         scores = parallel(\n\u001b[1;32m    435\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             for train, test in cv.split(X, y))\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m_rfe_single_fit\u001b[0;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     return rfe._fit(\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         _score(estimator, X_test[:, features], y_test, scorer)).scores_\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mcoefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'feature_importances_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcoefs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 raise RuntimeError('The classifier does not expose '\n\u001b[0m\u001b[1;32m    182\u001b[0m                                    \u001b[0;34m'\"coef_\" or \"feature_importances_\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                                    'attributes')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The classifier does not expose \"coef_\" or \"feature_importances_\" attributes"
     ]
    }
   ],
   "source": [
    "\n",
    "for species in MODEL_SPECIES:\n",
    "    display(HTML('<h5>=============== %s ======================</h5>' % species))\n",
    "    classifier_stats = []\n",
    "    model = Pipeline([('select_species', SelectSpecies(species)), \n",
    "                      ('ps_absence', FillPseudoAbsenceData()),\n",
    "                      ('fill_env', FillEnvironmentalData(VARIABLE_SET))]\n",
    "                     )\n",
    "    print(\"Constructing the dataset...\")\n",
    "    aux_result = model.fit_transform(original_presence_data)\n",
    "    X, y = aux_result[list(VARIABLE_SET)].values, list(map(int, ~aux_result.absence))\n",
    "    print(\"Dataset is formed.\")\n",
    "    aux_result.info()\n",
    "    for name, clf in CLASSIFIERS:\n",
    "        std_clf = make_pipeline(StandardScaler(), clf)\n",
    "        std_clf.coef_ = property(lambda x: x.named_steps.coef_)\n",
    "        std_clf.feature_importances_ = property(lambda x: x.steps[-1][-1].feature_importances_)\n",
    "        # Not yet completed!\n",
    "        print(\"Preforming recursive feature ellimination for the <%s> classifier...\" % name)\n",
    "        rfecv_acc = RFECV(estimator=std_clf, step=1, cv=StratifiedKFold(KFOLDS_NUMBER),\n",
    "                      scoring='accuracy')\n",
    "        rfecv_acc.fit(X, y)\n",
    "        print(\"=\" * 20, \"accuracy case\", \"=\" * 20)\n",
    "        print(\"Optimal composition of variables: \", np.array(VARIABLE_SET)[rfecv_acc.support_])\n",
    "        acc_score = np.array(rfecv_acc.grid_scores_)[np.argmax(rfecv_acc.grid_scores_)]\n",
    "        print(\"Composition score (acc): \", acc_score)\n",
    "        print(\"=\" * 60)\n",
    "        print(\"=\" * 20, \"roc/auc case\", \"=\" * 20)\n",
    "        rfecv_auc = RFECV(estimator=std_clf, step=1, cv=StratifiedKFold(KFOLDS_NUMBER),\n",
    "                      scoring='roc_auc')\n",
    "        rfecv_auc.fit(X, y)\n",
    "        print(\"Optimal composition of variables: \", np.array(VARIABLE_SET)[rfecv_auc.support_])\n",
    "        auc_score = np.array(rfecv_auc.grid_scores_)[np.argmax(rfecv_auc.grid_scores_)]\n",
    "        print(\"Composition score (auc): \", auc_score)\n",
    "        print(\"=\" * 60)\n",
    "        print(\"The following predictor composition was selected: \",  np.array(VARIABLE_SET)[rfecv_acc.support_])\n",
    "        classifier_stats.append((name, acc_score, clf))\n",
    "\n",
    "    optimal_name, optimal_score, optimal_clf = tuple(classifier_stats[np.argmax(map(lambda x: x[1], classifier_stats))])\n",
    "    print(\"The best classifier is %s. Its score is %s.\" % (optimal_name, optimal_score))\n",
    "    print(\"~\" * 90)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
