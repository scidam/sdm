{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic modelling module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "# make plots be included into this doc\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "from IPython.core.display import display, HTML\n",
    "from bin.model import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from bin.conf import PREDICTOR_LOADERS\n",
    "from bin.loader import get_predictor_data\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DATA_PATH = './data' # relative (or absolute) path to the data directory\n",
    "CSV_SEPARATOR = r';' # separator used in csv data files\n",
    "DATA_FILE_NAMES = ['all_species_final.csv',# all data files should be in the same format\n",
    "                   ] \n",
    "ALLOWED_COLUMNS = ['species', 'latitude', 'longitude'] # only these columns will be retained for computations\n",
    "COLUMNS_DTYPES = [np.str, np.float64, np.float64] # Should have the same length as ALLOWED_COLUMNS\n",
    "CLIMATIC_MODELS = ['50cc26','50cc85','50cc45', '70cc26', '70cc85','70cc45']\n",
    "CLIMATIC_MODELS = CLIMATIC_MODELS + list(map(lambda x: x.replace('cc', 'mc'), CLIMATIC_MODELS))\n",
    "CLIMATIC_MODELS = list(map(lambda x: '_' + x, CLIMATIC_MODELS))\n",
    "CLIMATIC_MODELS = ['_cclgm', '_ccmid']\n",
    "MODEL_SPECIES = [\n",
    "                 'quercus mongolica',\n",
    "                 'kalopanax septemlobus',\n",
    "                 'quercus',\n",
    "                 'quercus crispula',\n",
    "                 'fraxinus mandshurica'\n",
    "                ] # all  species should be given in lowercase format\n",
    "\n",
    "# Initial set of variables (see conf.py: PREDICTOR_LOADERS parameter for details)\n",
    "VARIABLE_SET = ('WKI5', 'PCKI0','PWKI0', 'CKI5', 'IT', 'IC')\n",
    "#VARIABLE_SET += tuple(['WIND' + str(k) for k in range(1, 13)])#\n",
    "#VARIABLE_SET = ('BIO1',)\n",
    "#VARIABLE_SET += tuple(['WKI' + str(k) for k in range(2, 7)])\n",
    "#VARIABLE_SET += tuple(['CKI' + str(k) for k in range(2, 7)])\n",
    "#VARIABLE_SET += tuple(['BIO' + str(k) for k in range(1, 4)])\n",
    "#VARIABLE_SET += ('PWKI0', 'PCKI0','IT', 'IC', 'TMINM', 'TMAXM')\n",
    "#VARIABLE_SET += tuple(['PREC' + str(k) for k in range(1, 13)])\n",
    "#VARIABLE_SET += tuple(['TAVG' + str(k) for k in range(1, 13)])\n",
    "#VARIABLE_SET += tuple(['TMIN' + str(k) for k in range(1, 13)])\n",
    "#VARIABLE_SET += tuple(['TMAX' + str(k) for k in range(1, 13)])\n",
    "VARIABLE_SET = tuple(set(VARIABLE_SET)) # remove duplicate variables if they are exist\n",
    "\n",
    "CLASSIFIERS = [# ('tree', DecisionTreeClassifier(random_state=10)),\n",
    "                ('MaxEnt', LogisticRegression()),\n",
    "                ('RandForest', RandomForestClassifier(n_estimators=100, random_state=10))\n",
    "                #('SVM', SVC(kernel='linear'))\n",
    "                #('LDA', LinearDiscriminantAnalysis())\n",
    "              ]\n",
    "KFOLDS_NUMBER = 20\n",
    "PSEUDO_ABSENCE_DENSITY = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file all_species_final.csv succesfully loaded.\n",
      "File overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4106 entries, 0 to 4105\n",
      "Data columns (total 3 columns):\n",
      "species      4106 non-null object\n",
      "latitude     4105 non-null float64\n",
      "longitude    4105 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 96.3+ KB\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Original size: 4106</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>The size after duplications removal: 2801</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_presence_data = pd.DataFrame({col: [] for col in ALLOWED_COLUMNS}) #initialize dataframe-accumulator\n",
    "for filename in DATA_FILE_NAMES:\n",
    "    try:\n",
    "        # data loading procedure\n",
    "        data = pd.read_csv(os.path.join(SOURCE_DATA_PATH, filename),\n",
    "                           sep=CSV_SEPARATOR, dtype={a:b for a,b in zip(ALLOWED_COLUMNS, COLUMNS_DTYPES)})\n",
    "    except IOError:\n",
    "        print(\"Couldn't read the file %s.\" % filename)\n",
    "    if any(data):\n",
    "        print('The file %s succesfully loaded.' % filename)\n",
    "        print('File overview:')\n",
    "        data.info()\n",
    "        print('='*50)\n",
    "    # data concatenation procedure\n",
    "    original_presence_data = pd.concat([original_presence_data, data[ALLOWED_COLUMNS]], ignore_index=True)\n",
    "\n",
    "# make species names lowercased and stripped\n",
    "original_presence_data['species'] = original_presence_data['species'].apply(str.lower).apply(str.strip)\n",
    "\n",
    "display(HTML('<h3>Original size: %s</h3>'%original_presence_data['species'].size))\n",
    "\n",
    "# remove duplicate rows and nan values\n",
    "original_presence_data = original_presence_data.dropna().drop_duplicates(ALLOWED_COLUMNS).reset_index(drop=True)\n",
    "display(HTML('<h3>The size after duplications removal: %s</h3>'%original_presence_data['species'].size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>General info:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2801 entries, 0 to 2800\n",
      "Data columns (total 3 columns):\n",
      "latitude     2801 non-null float64\n",
      "longitude    2801 non-null float64\n",
      "species      2801 non-null object\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 65.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Species occurences overview:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "kalopanax septemlobus     372\n",
       "carpinus cordata          331\n",
       "juglans mandshurica       316\n",
       "quercus crispula          264\n",
       "phellodendron amurense    235\n",
       "ulmus davidiana           223\n",
       "quercus mongolica         192\n",
       "acer mono                 187\n",
       "ulmus laciniata           165\n",
       "pinus koraiensis          157\n",
       "tilia amurensis           152\n",
       "fraxinus mandshurica      107\n",
       "fraxinus rhynchophylla     37\n",
       "abies holophylla           36\n",
       "juglans ailanthifolia      27\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(HTML('<h3>General info:</h3>'))\n",
    "original_presence_data.info()\n",
    "display(HTML('<h3>Species occurences overview:</h3>'))\n",
    "original_presence_data['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tocsv = original_presence_data[original_presence_data.species == 'kalopanax septemlobus']\n",
    "#tocsv.to_csv('kal.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN LOOP OVER ALL SPECIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>=============== quercus mongolica ======================</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:143: RuntimeWarning: invalid value encountered in less\n",
      "  inds = _ < vals_avg\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:69: RuntimeWarning: invalid value encountered in greater\n",
      "  result[vals > t] = result[vals > t] + vals[vals > t] - t\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:104: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any(vals < t):\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:106: RuntimeWarning: invalid value encountered in less\n",
      "  result[vals < t] = result[vals < t] + precs[vals < t]\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:75: RuntimeWarning: invalid value encountered in less\n",
      "  result[vals < t] = result[vals < t] + vals[vals < t] - t\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:97: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.any(vals > t):\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:99: RuntimeWarning: invalid value encountered in greater\n",
      "  result[vals > t] = result[vals > t] + precs[vals > t]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of ps-absence by cond: 1565\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13733 entries, 0 to 13732\n",
      "Data columns (total 9 columns):\n",
      "IC           13733 non-null float64\n",
      "IT           13733 non-null float64\n",
      "PCKI0        13733 non-null float64\n",
      "PWKI0        13733 non-null float64\n",
      "WKI5         13733 non-null float64\n",
      "absence      13733 non-null bool\n",
      "latitude     13733 non-null float64\n",
      "longitude    13733 non-null float64\n",
      "species      13733 non-null object\n",
      "dtypes: bool(1), float64(7), object(1)\n",
      "memory usage: 871.8+ KB\n",
      "Removed correlated features:  {'CKI5'}\n",
      "Leaved features:  {'IT', 'WKI5', 'IC', 'PWKI0', 'PCKI0'}\n",
      "Dataset is formed.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13733 entries, 0 to 13732\n",
      "Data columns (total 9 columns):\n",
      "IC           13733 non-null float64\n",
      "IT           13733 non-null float64\n",
      "PCKI0        13733 non-null float64\n",
      "PWKI0        13733 non-null float64\n",
      "WKI5         13733 non-null float64\n",
      "absence      13733 non-null bool\n",
      "latitude     13733 non-null float64\n",
      "longitude    13733 non-null float64\n",
      "species      13733 non-null object\n",
      "dtypes: bool(1), float64(7), object(1)\n",
      "memory usage: 871.8+ KB\n",
      "Preforming recursive feature ellimination for the <MaxEnt> classifier...\n",
      "Preforming recursive feature ellimination for the <RandForest> classifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h5> --------------- Summary for quercus mongolica: --------------- </h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best classifier is RandForest. Its accuracy score is 0.994464986918907.\n",
      "Optimal predictor set (acc):  ['IT' 'WKI5' 'IC' 'PWKI0' 'PCKI0']\n",
      "The best classifier is RandForest. Its roc/auc score is 0.98835002519938.\n",
      "Optimal predictor set (auc):  ['IT' 'WKI5' 'IC' 'PWKI0' 'PCKI0']\n",
      "Statistic over all classifiers: \n",
      "AUC/ROC - Case:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxEnt</th>\n",
       "      <th>RandForest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966586</td>\n",
       "      <td>0.98835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[IT, WKI5, IC, PWKI0, PCKI0]</td>\n",
       "      <td>[IT, WKI5, IC, PWKI0, PCKI0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MaxEnt                    RandForest\n",
       "0                      0.966586                       0.98835\n",
       "1  [IT, WKI5, IC, PWKI0, PCKI0]  [IT, WKI5, IC, PWKI0, PCKI0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision - Case:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxEnt</th>\n",
       "      <th>RandForest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.986311</td>\n",
       "      <td>0.994465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[IT, WKI5, IC]</td>\n",
       "      <td>[IT, WKI5, IC, PWKI0, PCKI0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MaxEnt                    RandForest\n",
       "0        0.986311                      0.994465\n",
       "1  [IT, WKI5, IC]  [IT, WKI5, IC, PWKI0, PCKI0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ </h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bands completed: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:143: RuntimeWarning: invalid value encountered in less\n",
      "  inds = _ < vals_avg\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:69: RuntimeWarning: invalid value encountered in greater\n",
      "  result[vals > t] = result[vals > t] + vals[vals > t] - t\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:97: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.any(vals > t):\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:99: RuntimeWarning: invalid value encountered in greater\n",
      "  result[vals > t] = result[vals > t] + precs[vals > t]\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:104: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any(vals < t):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bands completed: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:106: RuntimeWarning: invalid value encountered in less\n",
      "  result[vals < t] = result[vals < t] + precs[vals < t]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bands completed: 0.08\n",
      "Bands completed: 0.12\n",
      "Bands completed: 0.16\n",
      "Bands completed: 0.2\n",
      "Bands completed: 0.24\n",
      "Bands completed: 0.28\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'result' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/workspace/pacific_sdm/bin/loader.py\u001b[0m in \u001b[0;36mget_predictor_data\u001b[0;34m(lats, lons, name, postfix)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPREDICTOR_LOADERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostfix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpostfix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pacific_sdm/bin/loader.py\u001b[0m in \u001b[0;36mget_IT\u001b[0;34m(lats, lons, name, postfix)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_IT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostfix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mtmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_EXTCM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TMINCM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostfix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpostfix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0mtmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_EXTCM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TMAXCM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostfix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpostfix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pacific_sdm/bin/loader.py\u001b[0m in \u001b[0;36mget_EXTCM\u001b[0;34m(lats, lons, name, postfix)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0minds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mvals_avg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mvals_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bio_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpostfix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mvals_max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pacific_sdm/bin/loader.py\u001b[0m in \u001b[0;36mget_bio_data\u001b[0;34m(lats, lons, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xrot and yrot should be 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadAsArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/osgeo/gdal.py\u001b[0m in \u001b[0;36mReadAsArray\u001b[0;34m(self, xoff, yoff, xsize, ysize, buf_obj, buf_xsize, buf_ysize, buf_type, resample_alg, callback, callback_data)\u001b[0m\n\u001b[1;32m   1872\u001b[0m                                                \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m                                                callback_data = callback_data )\n\u001b[0m\u001b[1;32m   1874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/osgeo/gdal_array.py\u001b[0m in \u001b[0;36mDatasetReadAsArray\u001b[0;34m(ds, xoff, yoff, win_xsize, win_ysize, buf_obj, buf_xsize, buf_ysize, buf_type, resample_alg, callback, callback_data)\u001b[0m\n\u001b[1;32m    248\u001b[0m                                 \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                                 callback_data = callback_data )\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/osgeo/gdal_array.py\u001b[0m in \u001b[0;36mBandReadAsArray\u001b[0;34m(band, xoff, yoff, win_xsize, win_ysize, buf_xsize, buf_ysize, buf_type, buf_obj, resample_alg, callback, callback_data)\u001b[0m\n\u001b[1;32m    346\u001b[0m     if BandRasterIONumPy( band, 0, xoff, yoff, win_xsize, win_ysize,\n\u001b[0;32m--> 347\u001b[0;31m                           buf_obj, buf_type, resample_alg, callback, callback_data ) != 0:\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d94ec6f093ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m     fig1, ax = plot_map([22, 67], [100, 169], 5000, auc_optimal_clf,\n\u001b[1;32m     63\u001b[0m                             \u001b[0moptimal_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                             name=species, postfix='')\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mfig1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_size_inches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pacific_sdm/bin/model.py\u001b[0m in \u001b[0;36mplot_map\u001b[0;34m(lat_range, lon_range, resolution, clf, optimal_vars, train_df, name, postfix)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlats\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLATS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bands completed: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLATS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mpresence_proba_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pacific_sdm/bin/model.py\u001b[0m in \u001b[0;36mget_probabilities\u001b[0;34m(LATS, LONS)\u001b[0m\n\u001b[1;32m    274\u001b[0m                                'longitude': LONS_GRID.ravel()}\n\u001b[1;32m    275\u001b[0m                               )\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mfilled_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_env_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_nans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mXMAP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilled_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimal_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mnan_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXMAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pacific_sdm/bin/model.py\u001b[0m in \u001b[0;36mtransform_nans\u001b[0;34m(self, df, y)\u001b[0m\n\u001b[1;32m    200\u001b[0m             values = get_predictor_data(tuple(df_['latitude'].values),\n\u001b[1;32m    201\u001b[0m                                         \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                                         postfix=self.postfix_)\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0mdf_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pacific_sdm/bin/loader.py\u001b[0m in \u001b[0;36mget_predictor_data\u001b[0;34m(lats, lons, name, postfix)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPREDICTOR_LOADERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpostfix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The method for computation of %s isn't defined\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'result' referenced before assignment"
     ]
    }
   ],
   "source": [
    "for species in MODEL_SPECIES:\n",
    "    display(HTML('<h5>=============== %s ======================</h5>' % species))\n",
    "    classifier_stats_acc, classifier_stats_auc = [], []\n",
    "    model = Pipeline([('select_species', SelectSpecies(species)), \n",
    "                      ('prune_suspicious', PruneSuspiciousCoords()),\n",
    "                      ('ps_absence', FillPseudoAbsenceData(density=2)),\n",
    "                      ('fill_env', FillEnvironmentalData(VARIABLE_SET)),\n",
    "                      ('fill_by_cond', FillPseudoAbsenceByConditions(species=species,\n",
    "                                                                     similarity=0.1,\n",
    "                                                                     density=0.1,\n",
    "                                                                     area=[(22,100),(65,169)])),\n",
    "                      ('exclude_by_corr', CorrelationPruner(threshold=0.95, variables=VARIABLE_SET))\n",
    "                     ]\n",
    "                     )\n",
    "    print(\"Constructing the dataset...\")\n",
    "    aux_result = model.fit_transform(original_presence_data)\n",
    "    aux_result.info()\n",
    "    current_variable_set = set(VARIABLE_SET).intersection(set(aux_result.columns.values))\n",
    "    print(\"Removed correlated features: \", set(VARIABLE_SET) - current_variable_set)\n",
    "    print(\"Leaved features: \", current_variable_set)\n",
    "    current_variable_set = list(current_variable_set)\n",
    "    X, y = aux_result[current_variable_set].values, list(map(int, ~aux_result.absence))\n",
    "    print(\"Dataset is formed.\")\n",
    "    aux_result.info()\n",
    "    for name, clf in CLASSIFIERS:\n",
    "        std_clf = TweakedPipeline([('scaler', StandardScaler()),\n",
    "                         ('classificator', clf)])\n",
    "        print(\"Preforming recursive feature ellimination for the <%s> classifier...\" % name)\n",
    "        rfecv_acc = RFECV(estimator=std_clf, step=1, cv=StratifiedKFold(KFOLDS_NUMBER, shuffle=True),\n",
    "                      scoring='accuracy')\n",
    "        rfecv_acc.fit(X, y)\n",
    "        acc_score = np.array(rfecv_acc.grid_scores_)[np.argmax(rfecv_acc.grid_scores_)]\n",
    "        rfecv_auc = RFECV(estimator=std_clf, step=1, cv=StratifiedKFold(KFOLDS_NUMBER, shuffle=True),\n",
    "                      scoring='roc_auc')\n",
    "        rfecv_auc.fit(X, y)\n",
    "        auc_score = np.array(rfecv_auc.grid_scores_)[np.argmax(rfecv_auc.grid_scores_)]\n",
    "        classifier_stats_acc.append((name, acc_score, std_clf, rfecv_acc.support_))\n",
    "        classifier_stats_auc.append((name, auc_score, std_clf, rfecv_auc.support_))\n",
    "    acc_optimal_name, acc_optimal_score, acc_optimal_clf, acc_optimal_mask = tuple(classifier_stats_acc[np.argmax(list(map(lambda x: x[1], classifier_stats_acc)))])\n",
    "    auc_optimal_name, auc_optimal_score, auc_optimal_clf, auc_optimal_mask = tuple(classifier_stats_auc[np.argmax(list(map(lambda x: x[1], classifier_stats_auc)))])\n",
    "    display(HTML('<h5> --------------- Summary for %s: --------------- </h5>' % species))\n",
    "    print(\"The best classifier is %s. Its accuracy score is %s.\" % (acc_optimal_name, acc_optimal_score))\n",
    "    print(\"Optimal predictor set (acc): \",  np.array(current_variable_set)[acc_optimal_mask])\n",
    "    print(\"The best classifier is %s. Its roc/auc score is %s.\" % (auc_optimal_name, auc_optimal_score))\n",
    "    print(\"Optimal predictor set (auc): \",  np.array(current_variable_set)[auc_optimal_mask])\n",
    "    print(\"Statistic over all classifiers: \")\n",
    "    print(\"AUC/ROC - Case:\")\n",
    "    df = pd.DataFrame({n[0]: [n[1], np.array(current_variable_set)[n[-1]][:5]] for n in classifier_stats_auc})\n",
    "    display(df)\n",
    "    print(\"Precision - Case:\")\n",
    "    df = pd.DataFrame({n[0]: [n[1], np.array(current_variable_set)[n[-1]][:5]] for n in classifier_stats_acc})\n",
    "    display(df)\n",
    "    display(HTML('<h5> %s </h5>' % (\"~\" * 90,)))\n",
    "    \n",
    "    # ---- \n",
    "    #optimal_vars = list(np.array(current_variable_set)[auc_optimal_mask])\n",
    "    optimal_vars = current_variable_set\n",
    "    X, y = aux_result[optimal_vars].values, list(map(int, ~aux_result.absence))\n",
    "    auc_optimal_clf.fit(X, y)\n",
    "\n",
    "    \n",
    "    fig1, ax = plot_map([22, 67], [100, 169], 5000, auc_optimal_clf,\n",
    "                            optimal_vars, train_df=None,\n",
    "                            name=species, postfix='')\n",
    "    \n",
    "    fig1.set_size_inches(18.5, 10.5)\n",
    "    fig1.savefig('%s' % species + '_' + auc_optimal_name + '.png', dpi=600)\n",
    "    plt.close(fig1)\n",
    "    \n",
    "    gc.collect()\n",
    "    for cm in CLIMATIC_MODELS:\n",
    "        print(\"CURRENT MODEL:\", cm)\n",
    "        fig2, ax = plot_map([22, 67], [100, 169], 5000, auc_optimal_clf,\n",
    "                                optimal_vars, train_df=None,\n",
    "                                name='_'.join([species,cm,auc_optimal_name]), postfix=cm)\n",
    "        fig2.set_size_inches(18.5, 10.5)\n",
    "        fig2.savefig(cm+'_'+'%s'%species+'.png', dpi=600)\n",
    "        plt.close(fig2)\n",
    "        gc.collect()\n",
    "    plt.show()\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
