{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic modelling module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "# make plots be included into this doc\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.core.display import display, HTML\n",
    "from bin.model import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from bin.conf import PREDICTOR_LOADERS\n",
    "from bin.loader import get_predictor_data\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DATA_PATH = './data' # relative (or absolute) path to the data directory\n",
    "CSV_SEPARATOR = r';' # separator used in csv data files\n",
    "DATA_FILE_NAMES = ['Quercus.csv',# all data files should be in the same format\n",
    "                   'All_data.csv',\n",
    "                   'broad_leaf_GBIF.csv'\n",
    "                   ] \n",
    "ALLOWED_COLUMNS = ['species', 'latitude', 'longitude'] # only these columns will be retained for computations\n",
    "COLUMNS_DTYPES = [np.str, np.float64, np.float64] # Should have the same length as ALLOWED_COLUMNS\n",
    "CLIMATIC_MODELS = ['50cc26','50cc85','50cc45', '70cc26', '70cc85','70cc45']\n",
    "CLIMATIC_MODELS = CLIMATIC_MODELS + list(map(lambda x: x.replace('cc', 'mc'), CLIMATIC_MODELS))\n",
    "CLIMATIC_MODELS = map(lambda x: '_' + x, CLIMATIC_MODELS)\n",
    "MODEL_SPECIES = [#'quercus mongolica',\n",
    "                 'kalopanax septemlobus',\n",
    "#                 'quercus',\n",
    "#                 'quercus crispula',\n",
    "#                 'fraxinus mandshurica'\n",
    "                ] # all  species should be given in lowercase format\n",
    "\n",
    "# Initial set of variables (see conf.py: PREDICTOR_LOADERS parameter for details)\n",
    "VARIABLE_SET = ('WKI5', 'PCKI0','PWKI0', 'CKI5', 'IT', 'IC', 'TMINM', 'TMAXM')\n",
    "#VARIABLE_SET = ('IC', 'TMINM')\n",
    "#VARIABLE_SET += tuple(['WKI' + str(k) for k in range(2, 7)])\n",
    "#VARIABLE_SET += tuple(['CKI' + str(k) for k in range(2, 7)])\n",
    "#VARIABLE_SET = tuple(['BIO' + str(k) for k in range(1, 4)])\n",
    "#VARIABLE_SET += ('PWKI0', 'PCKI0','IT', 'IC', 'TMINM', 'TMAXM')\n",
    "#VARIABLE_SET = tuple(['PREC' + str(k) for k in range(1, 13)])\n",
    "#VARIABLE_SET += tuple(['TAVG' + str(k) for k in range(1, 13)])\n",
    "#VARIABLE_SET = tuple(['TMIN' + str(k) for k in range(1, 13)])\n",
    "#VARIABLE_SET = tuple(['TMAX' + str(k) for k in range(1, 13)])\n",
    "VARIABLE_SET = tuple(set(VARIABLE_SET)) # remove duplicate variables if they are exist\n",
    "\n",
    "CLASSIFIERS = [ ('tree', DecisionTreeClassifier(random_state=10)),\n",
    "                ('MaxEnt', LogisticRegression()),\n",
    "                #('SVM', SVC(kernel='linear'))\n",
    "                #('LDA', LinearDiscriminantAnalysis())\n",
    "              ]\n",
    "KFOLDS_NUMBER = 20\n",
    "PSEUDO_ABSENCE_DENSITY = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file Quercus.csv succesfully loaded.\n",
      "File overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 605 entries, 0 to 604\n",
      "Data columns (total 3 columns):\n",
      "species      605 non-null object\n",
      "latitude     604 non-null float64\n",
      "longitude    604 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 14.3+ KB\n",
      "==================================================\n",
      "The file All_data.csv succesfully loaded.\n",
      "File overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 3 columns):\n",
      "species      500 non-null object\n",
      "latitude     500 non-null float64\n",
      "longitude    500 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 11.8+ KB\n",
      "==================================================\n",
      "The file broad_leaf_GBIF.csv succesfully loaded.\n",
      "File overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3036 entries, 0 to 3035\n",
      "Data columns (total 4 columns):\n",
      "species        3036 non-null object\n",
      "countrycode    3036 non-null object\n",
      "latitude       3034 non-null float64\n",
      "longitude      3034 non-null float64\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 95.0+ KB\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Original size: 4141</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>The size after duplications removal: 2638</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_presence_data = pd.DataFrame({col: [] for col in ALLOWED_COLUMNS}) #initialize dataframe-accumulator\n",
    "for filename in DATA_FILE_NAMES:\n",
    "    try:\n",
    "        # data loading procedure\n",
    "        data = pd.read_csv(os.path.join(SOURCE_DATA_PATH, filename),\n",
    "                           sep=CSV_SEPARATOR, dtype={a:b for a,b in zip(ALLOWED_COLUMNS, COLUMNS_DTYPES)})\n",
    "    except IOError:\n",
    "        print(\"Couldn't read the file %s.\" % filename)\n",
    "    if any(data):\n",
    "        print('The file %s succesfully loaded.' % filename)\n",
    "        print('File overview:')\n",
    "        data.info()\n",
    "        print('='*50)\n",
    "    # data concatenation procedure\n",
    "    original_presence_data = pd.concat([original_presence_data, data[ALLOWED_COLUMNS]], ignore_index=True)\n",
    "\n",
    "# make species names lowercased and stripped\n",
    "original_presence_data['species'] = original_presence_data['species'].apply(str.lower).apply(str.strip)\n",
    "\n",
    "display(HTML('<h3>Original size: %s</h3>'%original_presence_data['species'].size))\n",
    "\n",
    "# remove duplicate rows and nan values\n",
    "original_presence_data = original_presence_data.dropna().drop_duplicates(ALLOWED_COLUMNS).reset_index(drop=True)\n",
    "display(HTML('<h3>The size after duplications removal: %s</h3>'%original_presence_data['species'].size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>General info:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2638 entries, 0 to 2637\n",
      "Data columns (total 3 columns):\n",
      "latitude     2638 non-null float64\n",
      "longitude    2638 non-null float64\n",
      "species      2638 non-null object\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 61.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Species occurences overview:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "kalopanax septemlobus     343\n",
       "quercus mongolica         328\n",
       "carpinus cordata          309\n",
       "juglans mandshurica       286\n",
       "fraxinus lanuginosa       274\n",
       "quercus crispula          266\n",
       "phellodendron amurense    221\n",
       "ulmus davidiana           130\n",
       "fraxinus mandshurica      103\n",
       "acer pictum                75\n",
       "ulmus japonica             62\n",
       "tilia amurensis            52\n",
       "acer mono                  52\n",
       "ulmus laciniata            44\n",
       "acer mayrii                28\n",
       "pinus koraiensis           23\n",
       "juglans ailanthifolia      22\n",
       "abies holophylla           17\n",
       "fraxinus rhynchophylla      3\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(HTML('<h3>General info:</h3>'))\n",
    "original_presence_data.info()\n",
    "display(HTML('<h3>Species occurences overview:</h3>'))\n",
    "original_presence_data['species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN LOOP OVER ALL SPECIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>=============== kalopanax septemlobus ======================</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:75: RuntimeWarning: invalid value encountered in less\n",
      "  result[vals < t] = result[vals < t] + vals[vals < t] - t\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:143: RuntimeWarning: invalid value encountered in less\n",
      "  inds = _ < vals_avg\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:97: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.any(vals > t):\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:99: RuntimeWarning: invalid value encountered in greater\n",
      "  result[vals > t] = result[vals > t] + precs[vals > t]\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:69: RuntimeWarning: invalid value encountered in greater\n",
      "  result[vals > t] = result[vals > t] + vals[vals > t] - t\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:104: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any(vals < t):\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:106: RuntimeWarning: invalid value encountered in less\n",
      "  result[vals < t] = result[vals < t] + precs[vals < t]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5693 entries, 0 to 5692\n",
      "Data columns (total 10 columns):\n",
      "absence      5693 non-null bool\n",
      "latitude     5693 non-null float64\n",
      "longitude    5693 non-null float64\n",
      "species      5693 non-null object\n",
      "TMAXM        5693 non-null float64\n",
      "CKI5         5693 non-null float64\n",
      "PWKI0        5693 non-null float64\n",
      "WKI5         5693 non-null float64\n",
      "IC           5693 non-null float64\n",
      "PCKI0        5693 non-null float64\n",
      "dtypes: bool(1), float64(8), object(1)\n",
      "memory usage: 405.9+ KB\n",
      "Removed correlated features:  {'IT', 'TMINM'}\n",
      "Leaved features:  {'TMAXM', 'CKI5', 'PWKI0', 'WKI5', 'PCKI0', 'IC'}\n",
      "Dataset is formed.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5693 entries, 0 to 5692\n",
      "Data columns (total 10 columns):\n",
      "absence      5693 non-null bool\n",
      "latitude     5693 non-null float64\n",
      "longitude    5693 non-null float64\n",
      "species      5693 non-null object\n",
      "TMAXM        5693 non-null float64\n",
      "CKI5         5693 non-null float64\n",
      "PWKI0        5693 non-null float64\n",
      "WKI5         5693 non-null float64\n",
      "IC           5693 non-null float64\n",
      "PCKI0        5693 non-null float64\n",
      "dtypes: bool(1), float64(8), object(1)\n",
      "memory usage: 405.9+ KB\n",
      "Preforming recursive feature ellimination for the <tree> classifier...\n",
      "Preforming recursive feature ellimination for the <MaxEnt> classifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h5> --------------- Summary for kalopanax septemlobus: --------------- </h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best classifier is tree. Its accuracy score is 0.9992976278724981.\n",
      "Optimal predictor set (acc):  ['TMAXM' 'PWKI0' 'WKI5' 'PCKI0' 'IC']\n",
      "The best classifier is MaxEnt. Its roc/auc score is 1.0.\n",
      "Optimal predictor set (auc):  ['TMAXM' 'CKI5' 'PWKI0' 'WKI5' 'PCKI0' 'IC']\n",
      "Statistic over all classifiers: \n",
      "AUC/ROC - Case:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxEnt</th>\n",
       "      <th>tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.998436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[TMAXM, CKI5, PWKI0, WKI5, PCKI0]</td>\n",
       "      <td>[TMAXM, PWKI0, WKI5, PCKI0, IC]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              MaxEnt                             tree\n",
       "0                                  1                         0.998436\n",
       "1  [TMAXM, CKI5, PWKI0, WKI5, PCKI0]  [TMAXM, PWKI0, WKI5, PCKI0, IC]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision - Case:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxEnt</th>\n",
       "      <th>tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.997013</td>\n",
       "      <td>0.999298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[TMAXM, CKI5, PWKI0, WKI5, PCKI0]</td>\n",
       "      <td>[TMAXM, PWKI0, WKI5, PCKI0, IC]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              MaxEnt                             tree\n",
       "0                           0.997013                         0.999298\n",
       "1  [TMAXM, CKI5, PWKI0, WKI5, PCKI0]  [TMAXM, PWKI0, WKI5, PCKI0, IC]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ </h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:75: RuntimeWarning: invalid value encountered in less\n",
      "  result[vals < t] = result[vals < t] + vals[vals < t] - t\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:97: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.any(vals > t):\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:99: RuntimeWarning: invalid value encountered in greater\n",
      "  result[vals > t] = result[vals > t] + precs[vals > t]\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:69: RuntimeWarning: invalid value encountered in greater\n",
      "  result[vals > t] = result[vals > t] + vals[vals > t] - t\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:104: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any(vals < t):\n",
      "/home/dmitry/workspace/pacific_sdm/bin/loader.py:106: RuntimeWarning: invalid value encountered in less\n",
      "  result[vals < t] = result[vals < t] + precs[vals < t]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT MODEL: _50cc26\n"
     ]
    }
   ],
   "source": [
    "for species in MODEL_SPECIES:\n",
    "    display(HTML('<h5>=============== %s ======================</h5>' % species))\n",
    "    classifier_stats_acc, classifier_stats_auc = [], []\n",
    "    model = Pipeline([('select_species', SelectSpecies(species)), \n",
    "                      ('prune_suspicious', PruneSuspiciousCoords()),\n",
    "                      ('ps_absence', FillPseudoAbsenceData(density=0.9)),\n",
    "                      ('fill_env', FillEnvironmentalData(VARIABLE_SET)),\n",
    "                  #    ('fill_by_cond', FillPseudoAbsenceByConditions(species=species,\n",
    "                  #                                                   similarity=0.2,\n",
    "                  #                                                   density=0.1,\n",
    "                  #                                                   area=[(22,100),(65,169)])),\n",
    "                      ('exclude_by_corr', CorrelationPruner(threshold=0.95, variables=VARIABLE_SET))\n",
    "                     ]\n",
    "                     )\n",
    "    print(\"Constructing the dataset...\")\n",
    "    aux_result = model.fit_transform(original_presence_data)\n",
    "    aux_result.info()\n",
    "    current_variable_set = set(VARIABLE_SET).intersection(set(aux_result.columns.values))\n",
    "    print(\"Removed correlated features: \", set(VARIABLE_SET) - current_variable_set)\n",
    "    print(\"Leaved features: \", current_variable_set)\n",
    "    current_variable_set = list(current_variable_set)\n",
    "    X, y = aux_result[current_variable_set].values, list(map(int, ~aux_result.absence))\n",
    "    print(\"Dataset is formed.\")\n",
    "    aux_result.info()\n",
    "    for name, clf in CLASSIFIERS:\n",
    "        std_clf = TweakedPipeline([('scaler', StandardScaler()),\n",
    "                         ('classificator', clf)])\n",
    "        print(\"Preforming recursive feature ellimination for the <%s> classifier...\" % name)\n",
    "        rfecv_acc = RFECV(estimator=std_clf, step=1, cv=StratifiedKFold(KFOLDS_NUMBER, shuffle=True),\n",
    "                      scoring='accuracy')\n",
    "        rfecv_acc.fit(X, y)\n",
    "        acc_score = np.array(rfecv_acc.grid_scores_)[np.argmax(rfecv_acc.grid_scores_)]\n",
    "        rfecv_auc = RFECV(estimator=std_clf, step=1, cv=StratifiedKFold(KFOLDS_NUMBER, shuffle=True),\n",
    "                      scoring='roc_auc')\n",
    "        rfecv_auc.fit(X, y)\n",
    "        auc_score = np.array(rfecv_auc.grid_scores_)[np.argmax(rfecv_auc.grid_scores_)]\n",
    "        classifier_stats_acc.append((name, acc_score, std_clf, rfecv_acc.support_))\n",
    "        classifier_stats_auc.append((name, auc_score, std_clf, rfecv_auc.support_))\n",
    "    acc_optimal_name, acc_optimal_score, acc_optimal_clf, acc_optimal_mask = tuple(classifier_stats_acc[np.argmax(list(map(lambda x: x[1], classifier_stats_acc)))])\n",
    "    auc_optimal_name, auc_optimal_score, auc_optimal_clf, auc_optimal_mask = tuple(classifier_stats_auc[np.argmax(list(map(lambda x: x[1], classifier_stats_auc)))])\n",
    "    display(HTML('<h5> --------------- Summary for %s: --------------- </h5>' % species))\n",
    "    print(\"The best classifier is %s. Its accuracy score is %s.\" % (acc_optimal_name, acc_optimal_score))\n",
    "    print(\"Optimal predictor set (acc): \",  np.array(current_variable_set)[acc_optimal_mask])\n",
    "    print(\"The best classifier is %s. Its roc/auc score is %s.\" % (auc_optimal_name, auc_optimal_score))\n",
    "    print(\"Optimal predictor set (auc): \",  np.array(current_variable_set)[auc_optimal_mask])\n",
    "    print(\"Statistic over all classifiers: \")\n",
    "    print(\"AUC/ROC - Case:\")\n",
    "    df = pd.DataFrame({n[0]: [n[1], np.array(current_variable_set)[n[-1]][:5]] for n in classifier_stats_auc})\n",
    "    display(df)\n",
    "    print(\"Precision - Case:\")\n",
    "    df = pd.DataFrame({n[0]: [n[1], np.array(current_variable_set)[n[-1]][:5]] for n in classifier_stats_acc})\n",
    "    display(df)\n",
    "    display(HTML('<h5> %s </h5>' % (\"~\" * 90,)))\n",
    "    \n",
    "    # ---- \n",
    "    #optimal_vars = list(np.array(current_variable_set)[auc_optimal_mask])\n",
    "    optimal_vars = current_variable_set\n",
    "    X, y = aux_result[optimal_vars].values, list(map(int, ~aux_result.absence))\n",
    "    auc_optimal_clf.fit(X, y)\n",
    "\n",
    "    \n",
    "    fig1, ax, XMAP = plot_map([22, 65], [100, 169], 500, auc_optimal_clf,\n",
    "                            optimal_vars, train_df=None,\n",
    "                            name='clf_'+auc_optimal_name+'_'+species, postfix='')\n",
    "    \n",
    "    fig1.set_size_inches(18.5, 10.5)\n",
    "    fig1.savefig('%s'%species+'_'+auc_optimal_name+ '.png', dpi=600)\n",
    "    plt.close(fig1)\n",
    "    \n",
    "    for cm in CLIMATIC_MODELS:\n",
    "        print(\"CURRENT MODEL:\", cm)\n",
    "        fig2, ax, XMAP = plot_map([22, 65], [100, 169], 500, auc_optimal_clf,\n",
    "                                optimal_vars, train_df=None,\n",
    "                                name='clf_'+auc_optimal_name+'_'+species, postfix=cm)\n",
    "        fig2.set_size_inches(18.5, 10.5)\n",
    "        fig2.savefig('FUTURE_'+'%s'%species+'_'+auc_optimal_name+ '.png', dpi=600)\n",
    "\n",
    "        plt.close(fig2)\n",
    "    #plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "     #predictions[~nan_mask, :] = auc_optimal_clf.predict_proba(XMAP[~nan_mask,:])\n",
    "     #presence_proba_current = predictions[:, 1]\n",
    "     #plt.figure()\n",
    "     #plt.contourf(LONS_GRID, LATS_GRID, presence_proba_current.reshape(1000,1000))\n",
    "     #plt.title('Present')\n",
    "     #plt.show()\n",
    "    \n",
    "#     fill_env = FillEnvironmentalData(optimal_vars, postfix='_50cc26')\n",
    "#     filled_df_f = fill_env.transform_nans(map_df)\n",
    "#     XMAP_f = filled_df_f.loc[:, optimal_vars].values\n",
    "#     nan_mask_future = np.any(np.isnan(XMAP_f), axis=1)\n",
    "#     predictions_future = np.zeros((len(nan_mask_future), 2)) * np.nan\n",
    "    \n",
    "#     predictions_future[~nan_mask_future, :] = auc_optimal_clf.predict_proba(XMAP_f[~nan_mask_future,:])\n",
    "#     presence_proba_future = predictions_future[:, 1]\n",
    "#     plt.figure()\n",
    "#     plt.contourf(LONS_GRID, LATS_GRID, presence_proba_future.reshape(1000,1000))\n",
    "#     plt.title('Future: 50cc26')\n",
    "#     plt.show()\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
