{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic modelling module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "# make plots be included into this doc\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "from IPython.core.display import display, HTML\n",
    "from bin.model import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from bin.conf import PREDICTOR_LOADERS\n",
    "from bin.loader import get_predictor_data\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DATA_PATH = './data' # relative (or absolute) path to the data directory\n",
    "CSV_SEPARATOR = r';' # separator used in csv data files\n",
    "DATA_FILE_NAMES = ['all_species_final.csv',# all data files should be in the same format\n",
    "                   ] \n",
    "ALLOWED_COLUMNS = ['species', 'latitude', 'longitude'] # only these columns will be retained for computations\n",
    "COLUMNS_DTYPES = [np.str, np.float64, np.float64] # Should have the same length as ALLOWED_COLUMNS\n",
    "CLIMATIC_MODELS = ['50cc26','50cc85','50cc45', '70cc26', '70cc85','70cc45']\n",
    "CLIMATIC_MODELS = CLIMATIC_MODELS + list(map(lambda x: x.replace('cc', 'mc'), CLIMATIC_MODELS))\n",
    "CLIMATIC_MODELS = list(map(lambda x: '_' + x, CLIMATIC_MODELS))\n",
    "CLIMATIC_MODELS = ['_cclgm', '_ccmid']\n",
    "MODEL_SPECIES = [\n",
    "                # 'quercus mongolica',\n",
    "                 'kalopanax septemlobus',\n",
    "                # 'quercus',\n",
    "                # 'quercus crispula',\n",
    "                # 'fraxinus mandshurica'\n",
    "                ] # all  species should be given in lowercase format\n",
    "\n",
    "# Initial set of variables (see conf.py: PREDICTOR_LOADERS parameter for details)\n",
    "VARIABLE_SET = ('WKI5', 'PCKI0','PWKI0', 'CKI5', 'IT', 'IC')\n",
    "#VARIABLE_SET += tuple(['WIND' + str(k) for k in range(1, 13)])#\n",
    "VARIABLE_SET = ('BIO1',)\n",
    "#VARIABLE_SET += tuple(['WKI' + str(k) for k in range(2, 7)])\n",
    "#VARIABLE_SET += tuple(['CKI' + str(k) for k in range(2, 7)])\n",
    "#VARIABLE_SET += tuple(['BIO' + str(k) for k in range(1, 4)])\n",
    "#VARIABLE_SET += ('PWKI0', 'PCKI0','IT', 'IC', 'TMINM', 'TMAXM')\n",
    "#VARIABLE_SET += tuple(['PREC' + str(k) for k in range(1, 13)])\n",
    "#VARIABLE_SET += tuple(['TAVG' + str(k) for k in range(1, 13)])\n",
    "#VARIABLE_SET += tuple(['TMIN' + str(k) for k in range(1, 13)])\n",
    "#VARIABLE_SET += tuple(['TMAX' + str(k) for k in range(1, 13)])\n",
    "VARIABLE_SET = tuple(set(VARIABLE_SET)) # remove duplicate variables if they are exist\n",
    "\n",
    "CLASSIFIERS = [# ('tree', DecisionTreeClassifier(random_state=10)),\n",
    "                ('MaxEnt', LogisticRegression()),\n",
    "                #('SVM', SVC(kernel='linear'))\n",
    "                #('LDA', LinearDiscriminantAnalysis())\n",
    "              ]\n",
    "KFOLDS_NUMBER = 20\n",
    "PSEUDO_ABSENCE_DENSITY = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file all_species_final.csv succesfully loaded.\n",
      "File overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4106 entries, 0 to 4105\n",
      "Data columns (total 3 columns):\n",
      "species      4106 non-null object\n",
      "latitude     4105 non-null float64\n",
      "longitude    4105 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 96.3+ KB\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Original size: 4106</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>The size after duplications removal: 2801</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_presence_data = pd.DataFrame({col: [] for col in ALLOWED_COLUMNS}) #initialize dataframe-accumulator\n",
    "for filename in DATA_FILE_NAMES:\n",
    "    try:\n",
    "        # data loading procedure\n",
    "        data = pd.read_csv(os.path.join(SOURCE_DATA_PATH, filename),\n",
    "                           sep=CSV_SEPARATOR, dtype={a:b for a,b in zip(ALLOWED_COLUMNS, COLUMNS_DTYPES)})\n",
    "    except IOError:\n",
    "        print(\"Couldn't read the file %s.\" % filename)\n",
    "    if any(data):\n",
    "        print('The file %s succesfully loaded.' % filename)\n",
    "        print('File overview:')\n",
    "        data.info()\n",
    "        print('='*50)\n",
    "    # data concatenation procedure\n",
    "    original_presence_data = pd.concat([original_presence_data, data[ALLOWED_COLUMNS]], ignore_index=True)\n",
    "\n",
    "# make species names lowercased and stripped\n",
    "original_presence_data['species'] = original_presence_data['species'].apply(str.lower).apply(str.strip)\n",
    "\n",
    "display(HTML('<h3>Original size: %s</h3>'%original_presence_data['species'].size))\n",
    "\n",
    "# remove duplicate rows and nan values\n",
    "original_presence_data = original_presence_data.dropna().drop_duplicates(ALLOWED_COLUMNS).reset_index(drop=True)\n",
    "display(HTML('<h3>The size after duplications removal: %s</h3>'%original_presence_data['species'].size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>General info:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2801 entries, 0 to 2800\n",
      "Data columns (total 3 columns):\n",
      "latitude     2801 non-null float64\n",
      "longitude    2801 non-null float64\n",
      "species      2801 non-null object\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 65.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Species occurences overview:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "kalopanax septemlobus     372\n",
       "carpinus cordata          331\n",
       "juglans mandshurica       316\n",
       "quercus crispula          264\n",
       "phellodendron amurense    235\n",
       "ulmus davidiana           223\n",
       "quercus mongolica         192\n",
       "acer mono                 187\n",
       "ulmus laciniata           165\n",
       "pinus koraiensis          157\n",
       "tilia amurensis           152\n",
       "fraxinus mandshurica      107\n",
       "fraxinus rhynchophylla     37\n",
       "abies holophylla           36\n",
       "juglans ailanthifolia      27\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(HTML('<h3>General info:</h3>'))\n",
    "original_presence_data.info()\n",
    "display(HTML('<h3>Species occurences overview:</h3>'))\n",
    "original_presence_data['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tocsv = original_presence_data[original_presence_data.species == 'kalopanax septemlobus']\n",
    "#tocsv.to_csv('kal.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN LOOP OVER ALL SPECIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>=============== kalopanax septemlobus ======================</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing the dataset...\n",
      "The number of ps-absence by cond: 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12179 entries, 0 to 12178\n",
      "Data columns (total 5 columns):\n",
      "BIO1         12179 non-null float64\n",
      "absence      12179 non-null bool\n",
      "latitude     12179 non-null float64\n",
      "longitude    12179 non-null float64\n",
      "species      12179 non-null object\n",
      "dtypes: bool(1), float64(3), object(1)\n",
      "memory usage: 392.6+ KB\n",
      "Removed correlated features:  set()\n",
      "Leaved features:  {'BIO1'}\n",
      "Dataset is formed.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12179 entries, 0 to 12178\n",
      "Data columns (total 5 columns):\n",
      "BIO1         12179 non-null float64\n",
      "absence      12179 non-null bool\n",
      "latitude     12179 non-null float64\n",
      "longitude    12179 non-null float64\n",
      "species      12179 non-null object\n",
      "dtypes: bool(1), float64(3), object(1)\n",
      "memory usage: 392.6+ KB\n",
      "Preforming recursive feature ellimination for the <MaxEnt> classifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h5> --------------- Summary for kalopanax septemlobus: --------------- </h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best classifier is MaxEnt. Its accuracy score is 0.987683915306922.\n",
      "Optimal predictor set (acc):  ['BIO1']\n",
      "The best classifier is MaxEnt. Its roc/auc score is 0.976180621906655.\n",
      "Optimal predictor set (auc):  ['BIO1']\n",
      "Statistic over all classifiers: \n",
      "AUC/ROC - Case:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxEnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.976181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[BIO1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MaxEnt\n",
       "0  0.976181\n",
       "1    [BIO1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision - Case:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxEnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[BIO1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MaxEnt\n",
       "0  0.987684\n",
       "1    [BIO1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ </h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'result' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/workspace/pacific_sdm/bin/loader.py\u001b[0m in \u001b[0;36mget_predictor_data\u001b[0;34m(lats, lons, name, postfix)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPREDICTOR_LOADERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostfix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpostfix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_bio_data() got an unexpected keyword argument 'postfix'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/workspace/pacific_sdm/bin/loader.py\u001b[0m in \u001b[0;36mget_predictor_data\u001b[0;34m(lats, lons, name, postfix)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPREDICTOR_LOADERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpostfix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pacific_sdm/bin/loader.py\u001b[0m in \u001b[0;36mget_bio_data\u001b[0;34m(lats, lons, name)\u001b[0m\n\u001b[1;32m     35\u001b[0m                                   \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                                   \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                                   xmin, xres, ymax, yres)\n",
      "\u001b[0;31mMemoryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c07339582ab4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m     fig1, ax, XMAP = plot_map([22, 67], [100, 169], 3000, auc_optimal_clf,\n\u001b[1;32m     63\u001b[0m                             \u001b[0moptimal_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                             name=species, postfix='')\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mfig1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_size_inches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pacific_sdm/bin/model.py\u001b[0m in \u001b[0;36mplot_map\u001b[0;34m(lat_range, lon_range, resolution, clf, optimal_vars, train_df, name, postfix)\u001b[0m\n\u001b[1;32m    274\u001b[0m                            'longitude': LONS_GRID.ravel()}\n\u001b[1;32m    275\u001b[0m                           )\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mfilled_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_env_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_nans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0mXMAP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilled_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimal_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0mnan_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXMAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pacific_sdm/bin/model.py\u001b[0m in \u001b[0;36mtransform_nans\u001b[0;34m(self, df, y)\u001b[0m\n\u001b[1;32m    200\u001b[0m             values = get_predictor_data(tuple(df_['latitude'].values),\n\u001b[1;32m    201\u001b[0m                                         \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                                         postfix=self.postfix_)\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0mdf_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pacific_sdm/bin/loader.py\u001b[0m in \u001b[0;36mget_predictor_data\u001b[0;34m(lats, lons, name, postfix)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPREDICTOR_LOADERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpostfix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The method for computation of %s isn't defined\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'result' referenced before assignment"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dmitry/.pyenv/versions/3.5.4/lib/python3.5/tkinter/__init__.py\", line 1558, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/home/dmitry/.pyenv/versions/3.5.4/lib/python3.5/tkinter/__init__.py\", line 605, in callit\n",
      "    func(*args)\n",
      "  File \"/home/dmitry/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/ipykernel/eventloops.py\", line 192, in on_timer\n",
      "    self.func()\n",
      "  File \"/home/dmitry/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 298, in do_one_iteration\n",
      "    stream.flush(zmq.POLLIN, 1)\n",
      "  File \"/home/dmitry/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 380, in flush\n",
      "    self._rebuild_io_state()\n",
      "  File \"/home/dmitry/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 503, in _rebuild_io_state\n",
      "    if self.socket is None:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "for species in MODEL_SPECIES:\n",
    "    display(HTML('<h5>=============== %s ======================</h5>' % species))\n",
    "    classifier_stats_acc, classifier_stats_auc = [], []\n",
    "    model = Pipeline([('select_species', SelectSpecies(species)), \n",
    "                      ('prune_suspicious', PruneSuspiciousCoords()),\n",
    "                      ('ps_absence', FillPseudoAbsenceData(density=2)),\n",
    "                      ('fill_env', FillEnvironmentalData(VARIABLE_SET)),\n",
    "                      ('fill_by_cond', FillPseudoAbsenceByConditions(species=species,\n",
    "                                                                     similarity=0.1,\n",
    "                                                                     density=0.1,\n",
    "                                                                     area=[(22,100),(65,169)])),\n",
    "                      ('exclude_by_corr', CorrelationPruner(threshold=0.95, variables=VARIABLE_SET))\n",
    "                     ]\n",
    "                     )\n",
    "    print(\"Constructing the dataset...\")\n",
    "    aux_result = model.fit_transform(original_presence_data)\n",
    "    aux_result.info()\n",
    "    current_variable_set = set(VARIABLE_SET).intersection(set(aux_result.columns.values))\n",
    "    print(\"Removed correlated features: \", set(VARIABLE_SET) - current_variable_set)\n",
    "    print(\"Leaved features: \", current_variable_set)\n",
    "    current_variable_set = list(current_variable_set)\n",
    "    X, y = aux_result[current_variable_set].values, list(map(int, ~aux_result.absence))\n",
    "    print(\"Dataset is formed.\")\n",
    "    aux_result.info()\n",
    "    for name, clf in CLASSIFIERS:\n",
    "        std_clf = TweakedPipeline([('scaler', StandardScaler()),\n",
    "                         ('classificator', clf)])\n",
    "        print(\"Preforming recursive feature ellimination for the <%s> classifier...\" % name)\n",
    "        rfecv_acc = RFECV(estimator=std_clf, step=1, cv=StratifiedKFold(KFOLDS_NUMBER, shuffle=True),\n",
    "                      scoring='accuracy')\n",
    "        rfecv_acc.fit(X, y)\n",
    "        acc_score = np.array(rfecv_acc.grid_scores_)[np.argmax(rfecv_acc.grid_scores_)]\n",
    "        rfecv_auc = RFECV(estimator=std_clf, step=1, cv=StratifiedKFold(KFOLDS_NUMBER, shuffle=True),\n",
    "                      scoring='roc_auc')\n",
    "        rfecv_auc.fit(X, y)\n",
    "        auc_score = np.array(rfecv_auc.grid_scores_)[np.argmax(rfecv_auc.grid_scores_)]\n",
    "        classifier_stats_acc.append((name, acc_score, std_clf, rfecv_acc.support_))\n",
    "        classifier_stats_auc.append((name, auc_score, std_clf, rfecv_auc.support_))\n",
    "    acc_optimal_name, acc_optimal_score, acc_optimal_clf, acc_optimal_mask = tuple(classifier_stats_acc[np.argmax(list(map(lambda x: x[1], classifier_stats_acc)))])\n",
    "    auc_optimal_name, auc_optimal_score, auc_optimal_clf, auc_optimal_mask = tuple(classifier_stats_auc[np.argmax(list(map(lambda x: x[1], classifier_stats_auc)))])\n",
    "    display(HTML('<h5> --------------- Summary for %s: --------------- </h5>' % species))\n",
    "    print(\"The best classifier is %s. Its accuracy score is %s.\" % (acc_optimal_name, acc_optimal_score))\n",
    "    print(\"Optimal predictor set (acc): \",  np.array(current_variable_set)[acc_optimal_mask])\n",
    "    print(\"The best classifier is %s. Its roc/auc score is %s.\" % (auc_optimal_name, auc_optimal_score))\n",
    "    print(\"Optimal predictor set (auc): \",  np.array(current_variable_set)[auc_optimal_mask])\n",
    "    print(\"Statistic over all classifiers: \")\n",
    "    print(\"AUC/ROC - Case:\")\n",
    "    df = pd.DataFrame({n[0]: [n[1], np.array(current_variable_set)[n[-1]][:5]] for n in classifier_stats_auc})\n",
    "    display(df)\n",
    "    print(\"Precision - Case:\")\n",
    "    df = pd.DataFrame({n[0]: [n[1], np.array(current_variable_set)[n[-1]][:5]] for n in classifier_stats_acc})\n",
    "    display(df)\n",
    "    display(HTML('<h5> %s </h5>' % (\"~\" * 90,)))\n",
    "    \n",
    "    # ---- \n",
    "    #optimal_vars = list(np.array(current_variable_set)[auc_optimal_mask])\n",
    "    optimal_vars = current_variable_set\n",
    "    X, y = aux_result[optimal_vars].values, list(map(int, ~aux_result.absence))\n",
    "    auc_optimal_clf.fit(X, y)\n",
    "\n",
    "    \n",
    "    fig1, ax, XMAP = plot_map([22, 67], [100, 169], 3000, auc_optimal_clf,\n",
    "                            optimal_vars, train_df=None,\n",
    "                            name=species, postfix='')\n",
    "    \n",
    "    fig1.set_size_inches(18.5, 10.5)\n",
    "    fig1.savefig('%s' % species + '_' + auc_optimal_name + '.png', dpi=300)\n",
    "    plt.close(fig1)\n",
    "    \n",
    "    gc.collect()\n",
    "    for cm in CLIMATIC_MODELS:\n",
    "        print(\"CURRENT MODEL:\", cm)\n",
    "        fig2, ax, XMAP = plot_map([22, 67], [100, 169], 3000, auc_optimal_clf,\n",
    "                                optimal_vars, train_df=None,\n",
    "                                name=species+cm, postfix=cm)\n",
    "        fig2.set_size_inches(18.5, 10.5)\n",
    "        fig2.savefig(cm+'_'+'%s'%species+'.png', dpi=300)\n",
    "        plt.close(fig2)\n",
    "        gc.collect()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "     #predictions[~nan_mask, :] = auc_optimal_clf.predict_proba(XMAP[~nan_mask,:])\n",
    "     #presence_proba_current = predictions[:, 1]\n",
    "     #plt.figure()\n",
    "     #plt.contourf(LONS_GRID, LATS_GRID, presence_proba_current.reshape(1000,1000))\n",
    "     #plt.title('Present')\n",
    "     #plt.show()\n",
    "    \n",
    "#     fill_env = FillEnvironmentalData(optimal_vars, postfix='_50cc26')\n",
    "#     filled_df_f = fill_env.transform_nans(map_df)\n",
    "#     XMAP_f = filled_df_f.loc[:, optimal_vars].values\n",
    "#     nan_mask_future = np.any(np.isnan(XMAP_f), axis=1)\n",
    "#     predictions_future = np.zeros((len(nan_mask_future), 2)) * np.nan\n",
    "    \n",
    "#     predictions_future[~nan_mask_future, :] = auc_optimal_clf.predict_proba(XMAP_f[~nan_mask_future,:])\n",
    "#     presence_proba_future = predictions_future[:, 1]\n",
    "#     plt.figure()\n",
    "#     plt.contourf(LONS_GRID, LATS_GRID, presence_proba_future.reshape(1000,1000))\n",
    "#     plt.title('Future: 50cc26')\n",
    "#     plt.show()\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
